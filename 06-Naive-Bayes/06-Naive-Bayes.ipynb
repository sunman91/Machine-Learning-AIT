{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Sunny Kumar Tuladhar\"\n",
    "ID = \"st122336\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 06: Generative Classifiers: Naive Bayes\n",
    "\n",
    "As discussed in class, a naive Bayes classifier works as follows.\n",
    "\n",
    "We are given a feature space $\\mathcal{X}$ that could be discrete, continuous, or a mix of discrete and continuous features.\n",
    "\n",
    "We are also given a discrete set $\\mathcal{Y} = { y_1, \\ldots,\n",
    "y_K }$ of exhaustive, mutually exclusive classes thought to be the provenance of a dataset elements $\\mathbf{x} \\in \\mathcal{X}$.\n",
    "\n",
    "What does it mean to say that the features come from the classes? Specifically, we mean that the observation $\\mathbf{x}^{(i)}$ is a random vector statistically dependent on a random variable $y^{(i)}$.\n",
    "\n",
    "This means that $\\mathbf{x}^{(i)} \\sim p(\\mathbf{x} \\mid y^{(i)})$, where $y^{(i)} \\in \\mathcal{Y}$ and $y^{(i)} \\sim p(y)$. $p(y)$, the *prior*, is assumed to be a multinomial distribution over the possible classes $\\mathcal{Y}$, but the class conditional distribution $p(\\mathbf{x} \\mid y)$ can be an arbitrarily complicated joint distribution over the feature space that is different for each $y \\in \\mathcal{Y}$.\n",
    "\n",
    "The random process just described, in which a $y$ is first sampled from a multinomial distribution over $\\mathcal{Y}$ then an $\\mathbf{x}$ is sampled from an arbitrary joint distribution over $\\mathcal{X}$ that is conditioned on $y$, is a *generative model* for the provenance of our dataset. It may not be a fully accurate model for how nature gave us our dataset, but we nevertheless assume that it is.\n",
    "\n",
    "With all those preliminaries, now, given a new sample $\\mathbf{x}$ assumed to have been generated by the same generative process, we estimate, for each $y \\in \\mathcal{Y}$, the *posterior* $p(y \\mid \\mathbf{x})$ using the following strategy:\n",
    "$$\\begin{eqnarray}\n",
    "p(y \\mid \\mathbf{x} ; \\theta) & = & \\frac{p(\\mathbf{x} \\mid y ; \\theta) p(y ; \\theta)}{p(\\mathbf{x} ; \\theta)} \\\\\n",
    "& \\propto & p(\\mathbf{x} \\mid y ; \\theta) p(y ; \\theta) \\\\\n",
    "& = & p(y ; \\theta) \\prod_j p(x_j \\mid y, x_1, \\ldots, x_{j-1} ; \\theta) \\\\\n",
    "& \\approx & p(y ; \\theta) \\prod_j p(x_j \\mid y ; \\theta).\n",
    "\\end{eqnarray}$$\n",
    "\n",
    "The critical assumption here (besides the story of the generative random process assumed to be the origin of our dataset) is the *naive Bayes assumption* that the approximation\n",
    "\n",
    "$$ p(x_j \\mid y, x_1, \\ldots, x_{j-1} ; \\theta) \\approx p(x_j \\mid y ; \\theta)$$\n",
    "\n",
    "is close enough to reality to be useful. Note that if the features are truly *conditionally independent of each other given the class*, then the naive Bayes classifier is an exact probabilistic classifier.\n",
    "\n",
    "So now we know that the parameters of a naive Bayes classifier will always include the parameters $\\phi_1, \\ldots, \\phi_k$ of the multinomial distribution over $\\mathcal{Y}$ plus the individual conditional feature distributions $p(x_j \\mid y)$. If $x_j$ is discrete, we can represent this conditional distribution using a simple table of probabilities, and if $x_j$ is continuous, we represent the conditional distribution using the parameters of some continuous distribution such as a univariate Gaussian, univariate exponential, etc.\n",
    "\n",
    "In today's lab, we will use naive Bayes to perform diabetes diagnosis and text classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Diabetes classification\n",
    "\n",
    "In this example we predict wheter a patient with specific diagnostic measurements has diabetes or not. The target classes $\\mathcal{Y} = { y_1, y_2 }$ correspond respectively to \"no diabetes\" and \"diabetes.\" As the features are continuous, we will model their conditional probabilities $p(x_j \\mid y ; \\theta)$ as univariate Gaussians with means $\\mu_{j,y}$ and standard deviations $\\sigma_{j,y}$.\n",
    "\n",
    "The data are originally from the U.S. National Institute of Diabetes and Digestive and Kidney Diseases (NIDDK) and are available from [Kaggle](https://www.kaggle.com/uciml/pima-indians-diabetes-database)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data manipulation\n",
    "\n",
    "First we have some functions to read the dataset, split it into train and test, and partition it according to target class ($y$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from CSV file\n",
    "def loadCsv(filename):\n",
    "    data_raw = pd.read_csv(filename)\n",
    "    headers = data_raw.columns\n",
    "    dataset = data_raw.values\n",
    "    return dataset, headers\n",
    "\n",
    "# Split dataset into test and train with given ratio\n",
    "def splitDataset(test_size,*arrays,**kwargs):\n",
    "    return train_test_split(*arrays,test_size=test_size,**kwargs)\n",
    "\n",
    "# Separate training data according to target class\n",
    "# Return key value pairs array in which keys are possible target variable values\n",
    "# and values are the data records.\n",
    "\n",
    "def data_split_byClass(dataset):\n",
    "    Xy = {}\n",
    "    for i in range(len(dataset)):\n",
    "        datapair = dataset[i]\n",
    "        # datapair[-1] (the last column) is the target class for this record.\n",
    "        # Check if we already have this value as a key in the return array\n",
    "        if (datapair[-1] not in Xy):\n",
    "            # Add class as key\n",
    "            Xy[datapair[-1]] = []\n",
    "        # Append this record to array of records for this class key\n",
    "        Xy[datapair[-1]].append(datapair)\n",
    "    return Xy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training\n",
    "\n",
    "Next we have some functions used for training the model. Parameters include the conditional means and standard deviations for each feature as well as the parameters of the multinomial distribution (more specifically the Bernoulli distribution since this is a binary classification problem) over $\\mathcal{Y}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Gaussian parameters mu and sigma for each attribute over a dataset\n",
    "\n",
    "def get_gaussian_parameters(X, y):\n",
    "    parameters = {}\n",
    "    unique_y = np.unique(y)\n",
    "    for uy in unique_y:\n",
    "        mean = np.mean(X[y==uy], axis=0)\n",
    "        std = np.std(X[y==uy], axis=0)\n",
    "        py = y[y==uy].size / y.size\n",
    "        parameters[uy] = { 'prior': py, 'mean': mean, 'std': std }\n",
    "    return parameters, unique_y\n",
    "\n",
    "def calculateProbability(x, mu, sigma):\n",
    "    sigma = np.diag(sigma**2)\n",
    "    x = x.reshape(-1,1)\n",
    "    mu = mu.reshape(-1,1)\n",
    "    exponent = np.exp(-1/2*(x-mu).T@np.linalg.inv(sigma)@(x-mu))\n",
    "    return ((1/(np.sqrt(((2*np.pi)**x.size)*np.linalg.det(sigma))))*exponent)[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model testing\n",
    "\n",
    "Next are some functions for testing the model on a test set and computing its accuracy. Note that `predict_one()` allows us to calculate $p(y \\mid \\mathbf{x} ; \\theta)$ with or without the prior, i.e., as either\n",
    "\n",
    "$$ p(y \\mid \\mathbf{x} ; \\theta) \\propto p(\\mathbf{x} \\mid y ; \\theta),$$\n",
    "\n",
    "which corresponds to the assumption that the priors $p(y)$ are equal, i.e., $p(y) = \\frac{1}{K}$ for all $y$, or\n",
    "\n",
    "$$ p(y \\mid \\mathbf{x} ; \\theta) \\propto p(\\mathbf{x} \\mid y ; \\theta) p(y ; \\theta),$$\n",
    "\n",
    "which correctly includes the prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class conditional probabilities for given input data vector\n",
    "\n",
    "def predict_one(x, parameters, unique_y, prior=True):\n",
    "    probabilities = []\n",
    "    for key in parameters.keys():\n",
    "        probabilities.append(calculateProbability\n",
    "                             (x, parameters[key]['mean'],\n",
    "                              parameters[key]['std']) * (parameters[key]['prior']**(float(prior))))\n",
    "    probabilities = np.array(probabilities)\n",
    "    return unique_y[np.argmax(probabilities)]\n",
    "\n",
    "def getPredictions(X, parameters, unique_y,prior=True):\n",
    "    predictions = []\n",
    "    for i in range(X.shape[0]):\n",
    "        predictions.append(predict_one(X[i],parameters,unique_y,prior))\n",
    "    return np.array(predictions)\n",
    "\n",
    "# Get accuracy for test set\n",
    "\n",
    "def getAccuracy(y, y_pred):\n",
    "    correct = len(y[y==y_pred])\n",
    "    return correct/y.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment\n",
    "\n",
    "Here we load the diabetes dataset, split it into training and test data, train a Gaussian NB model, and test the model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total = 768 Train = 460 Test = 308\n",
      "Accuracy with Prior = 0.737012987012987\n",
      "Accuracy without Prior = 0.7305194805194806\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "\n",
    "filename = 'diabetes.csv'\n",
    "dataset, headers = loadCsv(filename)\n",
    "#print(headers)\n",
    "#print(np.array(dataset)[0:5,:])\n",
    "\n",
    "# Split into training and test\n",
    "\n",
    "X_train,X_test,y_train,y_test = splitDataset(0.4,dataset[:,:-1],dataset[:,-1])\n",
    "print(\"Total =\",len(dataset),\"Train =\", len(X_train),\"Test =\",len(X_test))\n",
    "\n",
    "# Train model\n",
    "\n",
    "parameters, unique_y = get_gaussian_parameters(X_train,y_train)\n",
    "prediction = getPredictions(X_test,parameters,unique_y)\n",
    "print(\"Accuracy with Prior =\",getAccuracy(y_test,prediction))\n",
    "\n",
    "# Test model\n",
    "\n",
    "prediction = getPredictions(X_test,parameters,unique_y,prior = False)\n",
    "print(\"Accuracy without Prior =\",getAccuracy(y_test,prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a3bd3dab7f817a77ee363a831fc17c0c",
     "grade": false,
     "grade_id": "cell-9a740adb2ea13611",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "###  Exercise In lab / take home work (20 points)\n",
    "\n",
    "Find out the proportion of the records in your dataset are positive vs. negative.  Can we conclude that $p(y=1) = p(y=0)$? If not, we should use the version of the model in which we use the priors $p(y=1)$ and $p(y=0)$. Explain\n",
    "whether/how it improves the result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(y = 0) is 0.65\n",
      "p(y = 1) is 0.35\n"
     ]
    }
   ],
   "source": [
    "ratio0 = len(X_train[y_train==0])/len(y_train)\n",
    "ratio1 = len(X_train[y_train==1])/len(y_train)\n",
    "print('p(y = 0) is',np.round(ratio0,2))\n",
    "print('p(y = 1) is',np.round(ratio1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0cf1a770bb1ee9faa6961f202769b10e",
     "grade": true,
     "grade_id": "cell-c1a5f74a2d330b0c",
     "locked": false,
     "points": 15,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Prior = 73.7\n",
      "Accuracy without Prior = 73.05\n",
      "difference 0.6494\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# Train model\n",
    "\n",
    "parameters, unique_y = get_gaussian_parameters(X_train,y_train)\n",
    "\n",
    "prediction = getPredictions(X_test,parameters,unique_y,prior = True)\n",
    "Acc_Pr = getAccuracy(y_test,prediction)\n",
    "print(\"Accuracy with Prior =\",np.round(Acc_Pr,4) * 100 )\n",
    "\n",
    "# Test model\n",
    "prediction = getPredictions(X_test,parameters,unique_y,prior = False)\n",
    "Acc_noPr = getAccuracy(y_test,prediction)\n",
    "print(\"Accuracy without Prior =\",np.round(Acc_noPr,4) * 100)\n",
    "\n",
    "print('difference',np.round((Acc_Pr - Acc_noPr) * 100,4) )\n",
    "\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the accuracy increased slightly when using with prior\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5b04f2456b0a8818c347b33999e5ea68",
     "grade": false,
     "grade_id": "cell-a32adf75650dfd55",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "**Explain whether you can conclude that $p(y=1) = p(y=0)$? If not, add\n",
    "the priors $p(y=1)$ and $p(y=0)$ to your NB model and explain how it improves the result.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cannot conclude $p(y=1) = p(y=0)$ because their values are very different. p(y = 0) is 0.63 and p(y = 1) is 0.37. Which means there is a lot more of class 0 than class 1 in the dataset. \n",
    "Adding the priors improves the result as it also takes the probability distribution of the classes over entire dataset into consideration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Text classification\n",
    "\n",
    "This example has been adapted from a post by Jaya Aiyappan, available at\n",
    "[Analytics Vidhya](https://medium.com/analytics-vidhya/naive-bayes-classifier-for-text-classification-556fabaf252b#:~:text=The%20Naive%20Bayes%20classifier%20is,time%20and%20less%20training%20data).\n",
    "\n",
    "We will generate a small dataset of sentences that are classified as either \"statements\" or \"questions.\"\n",
    "\n",
    "We will assume that occurance and placement of words within a sentence are independent of each other, so the sentence \"this is my book\" will have the same features as the sentence \"is this my book.\" We will treat words without case sensitivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             sentence      class\n",
      "0               This is my novel book  statement\n",
      "1  this book has more than one author  statement\n",
      "2                     is this my book   question\n",
      "3                     They are novels  statement\n",
      "4             have you read this book   question\n",
      "5            who is the novels author   question\n",
      "6             what are the characters   question\n",
      "7       This is how I bought the book  statement\n",
      "8         I like fictional characters  statement\n",
      "9          what is your favorite book   question\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "                        sentence      class\n",
      "0               this is the book  statement\n",
      "1  who are the novels characters   question\n",
      "2             is this the author   question\n",
      "3                  I like apples       None\n"
     ]
    }
   ],
   "source": [
    "# Generate text data for two classes, \"statement\" and \"question\"\n",
    "\n",
    "text_train = [['This is my novel book', 'statement'],\n",
    "              ['this book has more than one author', 'statement'],\n",
    "              ['is this my book', 'question'],\n",
    "              ['They are novels', 'statement'],\n",
    "              ['have you read this book', 'question'],\n",
    "              ['who is the novels author', 'question'],\n",
    "              ['what are the characters', 'question'],\n",
    "              ['This is how I bought the book', 'statement'],\n",
    "              ['I like fictional characters', 'statement'],\n",
    "              ['what is your favorite book', 'question']]\n",
    "\n",
    "text_test = [['this is the book', 'statement'], \n",
    "             ['who are the novels characters', 'question'], \n",
    "             ['is this the author', 'question'],\n",
    "            ['I like apples']]\n",
    "\n",
    "# Load training and test data into pandas data frames\n",
    "\n",
    "training_data = pd.DataFrame(text_train, columns= ['sentence', 'class'])\n",
    "print(training_data)\n",
    "print('\\n------------------------------------------\\n')\n",
    "testing_data = pd.DataFrame(text_test, columns= ['sentence', 'class'])\n",
    "print(testing_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is my novel book</td>\n",
       "      <td>statement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this book has more than one author</td>\n",
       "      <td>statement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is this my book</td>\n",
       "      <td>question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>They are novels</td>\n",
       "      <td>statement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>have you read this book</td>\n",
       "      <td>question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>who is the novels author</td>\n",
       "      <td>question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>what are the characters</td>\n",
       "      <td>question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This is how I bought the book</td>\n",
       "      <td>statement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I like fictional characters</td>\n",
       "      <td>statement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>what is your favorite book</td>\n",
       "      <td>question</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             sentence      class\n",
       "0               This is my novel book  statement\n",
       "1  this book has more than one author  statement\n",
       "2                     is this my book   question\n",
       "3                     They are novels  statement\n",
       "4             have you read this book   question\n",
       "5            who is the novels author   question\n",
       "6             what are the characters   question\n",
       "7       This is how I bought the book  statement\n",
       "8         I like fictional characters  statement\n",
       "9          what is your favorite book   question"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt_docs = [train['sentence'] for index,train in training_data.iterrows() \n",
    "             if train['class'] == 'statement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partition training data by class\n",
    "\n",
    "stmt_docs = [train['sentence'] for index,train in training_data.iterrows() \n",
    "             if train['class'] == 'statement']\n",
    "question_docs = [train['sentence'] for index,train in training_data.iterrows()\n",
    "                 if train['class'] == 'question']\n",
    "all_docs = [train['sentence'] for index,train in training_data.iterrows()]\n",
    "\n",
    "# Get word frequencies for each sentence and class\n",
    "\n",
    "def get_words(text):\n",
    "    # Initialize word list\n",
    "    words = [];\n",
    "    # Loop through each sentence in input array\n",
    "    for text_row in text:       \n",
    "        # Check the number of words. Assume each word is separated by a blank space\n",
    "        # so that the number of words is the number of blank spaces + 1\n",
    "        number_of_spaces = text_row.count(' ')\n",
    "        # loop through the sentence and get words between blank spaces.\n",
    "        for i in range(number_of_spaces):\n",
    "            # Check for for last word\n",
    "            words.append([text_row[:text_row.index(' ')].lower()])\n",
    "            text_row = text_row[text_row.index(' ')+1:]  \n",
    "            i = i + 1        \n",
    "        words.append([text_row])\n",
    "    return np.unique(words)\n",
    "\n",
    "# Get frequency of each word in each document\n",
    "\n",
    "def get_doc_word_frequency(words, text):  \n",
    "    word_freq_table = np.zeros((len(text),len(words)), dtype=int)\n",
    "    i = 0\n",
    "    for text_row in text:\n",
    "        # Insert extra space between each pair of words to prevent\n",
    "        # partial match of words\n",
    "        text_row_temp = ''\n",
    "        for idx, val in enumerate(text_row):\n",
    "            if val == ' ':\n",
    "                 text_row_temp = text_row_temp + '  '\n",
    "            else:\n",
    "                  text_row_temp = text_row_temp + val.lower()\n",
    "        text_row = ' ' + text_row_temp + ' '\n",
    "        j = 0\n",
    "        for word in words: \n",
    "            word = ' ' + word + ' '\n",
    "            freq = text_row.count(word)\n",
    "            word_freq_table[i,j] = freq\n",
    "            j = j + 1\n",
    "        i = i + 1\n",
    "    \n",
    "    return word_freq_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['are' 'author' 'book' 'bought' 'characters' 'fictional' 'has' 'how' 'i'\n",
      " 'is' 'like' 'more' 'my' 'novel' 'novels' 'one' 'than' 'the' 'they' 'this']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>are</th>\n",
       "      <th>author</th>\n",
       "      <th>book</th>\n",
       "      <th>bought</th>\n",
       "      <th>characters</th>\n",
       "      <th>fictional</th>\n",
       "      <th>has</th>\n",
       "      <th>how</th>\n",
       "      <th>i</th>\n",
       "      <th>is</th>\n",
       "      <th>like</th>\n",
       "      <th>more</th>\n",
       "      <th>my</th>\n",
       "      <th>novel</th>\n",
       "      <th>novels</th>\n",
       "      <th>one</th>\n",
       "      <th>than</th>\n",
       "      <th>the</th>\n",
       "      <th>they</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   are  author  book  bought  characters  fictional  has  how  i  is  like  \\\n",
       "0    0       0     1       0           0          0    0    0  0   1     0   \n",
       "1    0       1     1       0           0          0    1    0  0   0     0   \n",
       "2    1       0     0       0           0          0    0    0  0   0     0   \n",
       "3    0       0     1       1           0          0    0    1  1   1     0   \n",
       "4    0       0     0       0           1          1    0    0  1   0     1   \n",
       "\n",
       "   more  my  novel  novels  one  than  the  they  this  \n",
       "0     0   1      1       0    0     0    0     0     1  \n",
       "1     1   0      0       0    1     1    0     0     1  \n",
       "2     0   0      0       1    0     0    0     1     0  \n",
       "3     0   0      0       0    0     0    1     0     1  \n",
       "4     0   0      0       0    0     0    0     0     0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get word frequencies for statement documents\n",
    "word_list_s = get_words(stmt_docs)\n",
    "print(word_list_s)\n",
    "word_freq_table_s = get_doc_word_frequency(word_list_s, stmt_docs)\n",
    "tdm_s = pd.DataFrame(word_freq_table_s, columns=word_list_s)\n",
    "tdm_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'are': 1, 'author': 1, 'book': 3, 'bought': 1, 'characters': 1, 'fictional': 1, 'has': 1, 'how': 1, 'i': 2, 'is': 2, 'like': 1, 'more': 1, 'my': 1, 'novel': 1, 'novels': 1, 'one': 1, 'than': 1, 'the': 1, 'they': 1, 'this': 3}\n"
     ]
    }
   ],
   "source": [
    "# Get word frequencies over all statement documents\n",
    "\n",
    "freq_list_s = word_freq_table_s.sum(axis=0) \n",
    "freq_s = dict(zip(word_list_s,freq_list_s))\n",
    "print(freq_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>are</th>\n",
       "      <th>author</th>\n",
       "      <th>book</th>\n",
       "      <th>characters</th>\n",
       "      <th>favorite</th>\n",
       "      <th>have</th>\n",
       "      <th>is</th>\n",
       "      <th>my</th>\n",
       "      <th>novels</th>\n",
       "      <th>read</th>\n",
       "      <th>the</th>\n",
       "      <th>this</th>\n",
       "      <th>what</th>\n",
       "      <th>who</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   are  author  book  characters  favorite  have  is  my  novels  read  the  \\\n",
       "0    0       0     1           0         0     0   1   1       0     0    0   \n",
       "1    0       0     1           0         0     1   0   0       0     1    0   \n",
       "2    0       1     0           0         0     0   1   0       1     0    1   \n",
       "3    1       0     0           1         0     0   0   0       0     0    1   \n",
       "4    0       0     1           0         1     0   1   0       0     0    0   \n",
       "\n",
       "   this  what  who  you  your  \n",
       "0     1     0    0    0     0  \n",
       "1     1     0    0    1     0  \n",
       "2     0     0    1    0     0  \n",
       "3     0     1    0    0     0  \n",
       "4     0     1    0    0     1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get word frequencies for question documents\n",
    "\n",
    "word_list_q = get_words(question_docs)\n",
    "word_freq_table_q = get_doc_word_frequency(word_list_q, question_docs)\n",
    "tdm_q = pd.DataFrame(word_freq_table_q, columns=word_list_q)\n",
    "tdm_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'are': 1, 'author': 1, 'book': 3, 'characters': 1, 'favorite': 1, 'have': 1, 'is': 3, 'my': 1, 'novels': 1, 'read': 1, 'the': 2, 'this': 2, 'what': 2, 'who': 1, 'you': 1, 'your': 1}\n"
     ]
    }
   ],
   "source": [
    "# Get word frequencies over all question documents\n",
    "\n",
    "freq_list_q = word_freq_table_q.sum(axis=0) \n",
    "freq_q = dict(zip(word_list_q,freq_list_q))\n",
    "print(freq_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of words for \"statement\" class \n",
      "\n",
      "{'are': 0.043478260869565216, 'author': 0.043478260869565216, 'book': 0.08695652173913043, 'bought': 0.043478260869565216, 'characters': 0.043478260869565216, 'fictional': 0.043478260869565216, 'has': 0.043478260869565216, 'how': 0.043478260869565216, 'i': 0.06521739130434782, 'is': 0.06521739130434782, 'like': 0.043478260869565216, 'more': 0.043478260869565216, 'my': 0.043478260869565216, 'novel': 0.043478260869565216, 'novels': 0.043478260869565216, 'one': 0.043478260869565216, 'than': 0.043478260869565216, 'the': 0.043478260869565216, 'they': 0.043478260869565216, 'this': 0.08695652173913043}\n",
      "------------------------------------------- \n",
      "\n",
      "Probability of words for \"question\" class \n",
      "\n",
      "{'are': 0.05128205128205128, 'author': 0.05128205128205128, 'book': 0.10256410256410256, 'characters': 0.05128205128205128, 'favorite': 0.05128205128205128, 'have': 0.05128205128205128, 'is': 0.10256410256410256, 'my': 0.05128205128205128, 'novels': 0.05128205128205128, 'read': 0.05128205128205128, 'the': 0.07692307692307693, 'this': 0.07692307692307693, 'what': 0.07692307692307693, 'who': 0.05128205128205128, 'you': 0.05128205128205128, 'your': 0.05128205128205128}\n"
     ]
    }
   ],
   "source": [
    "# Get word probabilities for statement class\n",
    "a = 1\n",
    "prob_s = []\n",
    "for count in freq_list_s:\n",
    "    #print(word, count)\n",
    "    prob_s.append((count+a)/(sum(freq_list_s)+len(freq_list_s)*a))\n",
    "prob_s.append(a/(sum(freq_list_s)+len(freq_list_s)*a))\n",
    "    \n",
    "# Get word probabilities for question class\n",
    "\n",
    "prob_q = []\n",
    "for count in freq_list_q:\n",
    "    prob_q.append((count+a)/(sum(freq_list_q)+len(freq_list_q)*a))\n",
    "prob_q.append(a/(sum(freq_list_q)+len(freq_list_q)*a))   \n",
    "    \n",
    "    \n",
    "print('Probability of words for \"statement\" class \\n')\n",
    "print(dict(zip(word_list_s, prob_s)))\n",
    "print('------------------------------------------- \\n')\n",
    "print('Probability of words for \"question\" class \\n')\n",
    "print(dict(zip(word_list_q, prob_q)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate prior for one class\n",
    "\n",
    "def prior(className):    \n",
    "    denominator = len(stmt_docs) + len(question_docs)\n",
    "    \n",
    "    if className == 'statement':\n",
    "        numerator =  len(stmt_docs)\n",
    "    else:\n",
    "        numerator =  len(question_docs)\n",
    "        \n",
    "    return np.divide(numerator,denominator)\n",
    "    \n",
    "# Calculate class conditional probability for a sentence\n",
    "    \n",
    "def classCondProb(sentence, className):\n",
    "    words = get_words(sentence)\n",
    "    prob = 1\n",
    "    for word in words:\n",
    "            if className == 'statement':\n",
    "                idx = np.array(np.where(word_list_s == word))              \n",
    "                prob = (prob * prob_s[idx[0,0]]) \n",
    "              \n",
    "            else:\n",
    "                idx = np.array(np.where(word_list_q == word))\n",
    "                prob = (prob * prob_q[idx[0,0]]) \n",
    "    \n",
    "    return prob\n",
    "\n",
    "# Predict class of a sentence\n",
    "\n",
    "def predict(sentence):\n",
    "    prob_statement = classCondProb(sentence, 'statement') * prior('statement')\n",
    "    prob_question = classCondProb(sentence, 'question') * prior('question')\n",
    "    if  prob_statement > prob_question:\n",
    "        return 'statement'\n",
    "    else:\n",
    "        return 'question'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "06f31d4f4657c9d7a61ca287b3a51c86",
     "grade": false,
     "grade_id": "cell-3b166fac02ec4711",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### In-lab exercise: Laplace smoothing\n",
    "\n",
    "Run the code below and figure out why it fails.\n",
    "\n",
    "When a word does not appear with a specific class in the training data, its class-conditional probability is 0, and we are unable to\n",
    "get a reasonable probability for that class.\n",
    "\n",
    "Research Laplace smoothing, and modify the code above to implement Laplace smoothing (setting the frequency of all words with frequency 0 to a frequency of 1).\n",
    "Run the modified code on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting prediction for who are the novels characters\"\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 1 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8543/3413041565.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_docs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Getting prediction for %s\"'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_8543/1737167865.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mprob_statement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassCondProb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'statement'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'statement'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mprob_question\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassCondProb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'question'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'question'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mif\u001b[0m  \u001b[0mprob_statement\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mprob_question\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_8543/1737167865.py\u001b[0m in \u001b[0;36mclassCondProb\u001b[0;34m(sentence, className)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mclassName\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'statement'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_list_s\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                 \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mprob_s\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 1 with size 0"
     ]
    }
   ],
   "source": [
    "test_docs = list([test['sentence'] for index,test in testing_data.iterrows()])\n",
    "doc = test_docs[1]\n",
    "print('Getting prediction for %s\"' % doc)\n",
    "predict(doc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c92cc1750ff6519f167950df416dbad7",
     "grade": false,
     "grade_id": "cell-9d86c9d269d1a550",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 1.1 (10 points)\n",
    "\n",
    "Explain Why it failed and explain how to solve the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7a8b94cb831bb4a934e82d63cdf77be3",
     "grade": false,
     "grade_id": "cell-d424d31d1e17fd89",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "Explanation here! (Double click to explain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It fails because one of the word count was zero at this line \n",
    "\n",
    "`idx = np.array(np.where(word_list_s == word))`\n",
    "\n",
    "This would return nothing to the idx value. Hence the error \"index 0 is out of bounds for axis 1 with size 0\" and thus make the function not work.\n",
    "\n",
    "To fix this problem we can use Laplace smoothing.\n",
    "Laplace smoothing adds words to each class that appears in other class \n",
    "but not in its own with a count 1.\n",
    "We also increase the count of other words by 1 so as not to change the overall probabilities much. This means we will always a non zero value returned.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7f4d19cfc5939c6b387baa24d638bbfd",
     "grade": false,
     "grade_id": "cell-e17217b48752c1fe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 1.2 (20 points)\n",
    "\n",
    "Modify the code to make it work using Laplace smoothing. Include the functions `prior()`, `classCondProb()`, and `predict()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e51fedc8aefb2614a7936134d6333f67",
     "grade": false,
     "grade_id": "cell-0722e2f212d3751c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "a = 1\n",
    "prob_s = []\n",
    "for count in freq_list_s:\n",
    "    #print(word, count)\n",
    "    prob_s.append((count+a)/(sum(freq_list_s)+len(freq_list_s)*a))\n",
    "    \n",
    "prob_s.append(a/(sum(freq_list_s)+len(freq_list_s)*a))\n",
    "    \n",
    "# Get word probabilities for question class\n",
    "\n",
    "prob_q = []\n",
    "for count in freq_list_q:\n",
    "    prob_q.append((count+a)/(sum(freq_list_q)+len(freq_list_q)*a))\n",
    "    \n",
    "prob_q.append(a/(sum(freq_list_q)+len(freq_list_q)*a))   \n",
    "\n",
    "\n",
    "def prior(className):    \n",
    "    denominator = len(stmt_docs) + len(question_docs)\n",
    "    \n",
    "    if className == 'statement':\n",
    "        numerator =  len(stmt_docs)\n",
    "    else:\n",
    "        numerator =  len(question_docs)\n",
    "        \n",
    "    return np.divide(numerator,denominator)\n",
    "    \n",
    "# Calculate class conditional probability for a sentence\n",
    "    \n",
    "def classCondProb(sentence, className):\n",
    "    words = get_words(sentence)\n",
    "    prob = 1\n",
    "    for word in words:\n",
    "            if className == 'statement':\n",
    "                idx = np.where(word_list_s == word)\n",
    "                \n",
    "                if np.array(idx).shape[1] != 0: \n",
    "                    prob = (prob * prob_s[np.array(idx)[0,0]]) \n",
    "                else:\n",
    "                    prob = (prob * prob_s[-1])\n",
    "                    \n",
    "            else: #if className is question\n",
    "                idx = np.where(word_list_q == word)\n",
    "                \n",
    "                if np.array(idx).shape[1] != 0: \n",
    "                    prob = (prob * prob_q[np.array(idx)[0,0]]) \n",
    "                else:\n",
    "                    prob = (prob * prob_q[-1])\n",
    "                \n",
    "    \n",
    "    return prob\n",
    "\n",
    "# Predict class of a sentence\n",
    "\n",
    "def predict(sentence):\n",
    "    prob_statement = classCondProb(sentence, 'statement') * prior('statement')\n",
    "    prob_question = classCondProb(sentence, 'question') * prior('question')\n",
    "    if  prob_statement > prob_question:\n",
    "        return 'statement'\n",
    "    else:\n",
    "        return 'question'\n",
    "    \n",
    "\n",
    "\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b12f4c8d6b4163d2f6cfe464b3ba62f3",
     "grade": true,
     "grade_id": "cell-c576e7ed4dd3046a",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting prediction for this is the book\"\n",
      "question\n",
      "Getting prediction for who are the novels characters\"\n",
      "question\n",
      "Getting prediction for is this the author\"\n",
      "question\n",
      "Getting prediction for I like apples\"\n",
      "question\n",
      "success!\n"
     ]
    }
   ],
   "source": [
    "# Test function: Do not remove\n",
    "test_docs = list([test['sentence'] for index,test in testing_data.iterrows()])\n",
    "\n",
    "for sentence in test_docs:\n",
    "    print('Getting prediction for %s\"' % sentence)\n",
    "    print(predict(sentence))\n",
    "    \n",
    "print(\"success!\")\n",
    "# End Test function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7bc64c1be2ccb3ebb1e830d4b1d49384",
     "grade": false,
     "grade_id": "cell-12db07859804f68d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expected result**:\\\n",
    "Getting prediction for this is the book\"\\\n",
    "question\\\n",
    "Getting prediction for who are the novels characters\"\\\n",
    "question\\\n",
    "Getting prediction for is this the author\"\\\n",
    "question\\\n",
    "Getting prediction for I like apples\"\\\n",
    "statement\\\n",
    "success!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2e27454c64c5d71ac929177407bd2f10",
     "grade": false,
     "grade_id": "cell-2bc1a154cce1dd7a",
     "locked": true,
     "points": 50,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### Take home exercise\n",
    "\n",
    "Find a more substantial text classification dataset, clean up the documents, and build your NB classifier. Write a brief report on your in-lab and take home exercises and results here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TAKE HOME\n",
    "\n",
    "The dataset is from [Kaggle](https://www.kaggle.com/shahrukhkhan/questions-vs-statementsclassificationdataset?select=val.csv). We are just going to use the validation set and only a part of it \n",
    "becuase it is too huge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['How many did snow fall in Palermo between 1940and the 2000s?',\n",
       "        1],\n",
       "       ['When did the Egyptian and Syrian armies launch a surprise attack against Israeli forces',\n",
       "        1],\n",
       "       [' Still, the political ramifications of removing Hussein would have broadened the scope of the conflict greatly, and many coalition nations refused to participate in such an action, believing it would create a power vacuum and destabilize the region.',\n",
       "        0],\n",
       "       ['What did Simpson help construct with Bell?', 1],\n",
       "       ['How much did 1941 earn in the US', 1]], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "filename = 'val.csv'\n",
    "dataset, headers = loadCsv(filename)\n",
    "dataset = dataset[:1000,1:] #we will only use 1000 sentences\n",
    "\n",
    "#the dataset is the classification of sentences into statements or questions\n",
    "# 0 is a statement and 1 is a question as we can see below\n",
    "dataset[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing all special characters and numbers and then converting all to lower case\n",
    "for i in range(dataset.shape[0]):\n",
    "    dataset[i,0] = re.sub(r\"[^a-z]\",\" \",dataset[i,0].lower())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 1], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[:5,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total = 1000 \n",
      "Train = 600 \n",
      "Test = 400\n"
     ]
    }
   ],
   "source": [
    "# Split into training and test\n",
    "\n",
    "X_train,X_test,y_train,y_test = splitDataset(0.4,dataset[:,:-1],\n",
    "                                             dataset[:,-1])\n",
    "print(\"Total =\",len(dataset),\n",
    "      \"\\nTrain =\", len(X_train),\n",
    "      \"\\nTest =\",len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_docs = (X_train[y_train == 0]).reshape(-1).tolist()\n",
    "q_docs = (X_train[y_train == 1]).reshape(-1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 131),\n",
       " ('aaron', 1),\n",
       " ('abandoned', 1),\n",
       " ('abbreviations', 1),\n",
       " ('abortive', 1),\n",
       " ('about', 8),\n",
       " ('absolutely', 1),\n",
       " ('accepted', 1),\n",
       " ('accident', 1),\n",
       " ('accidental', 1),\n",
       " ('accompanied', 2),\n",
       " ('according', 1),\n",
       " ('account', 1),\n",
       " ('accounting', 1),\n",
       " ('accusative', 1),\n",
       " ('accused', 1),\n",
       " ('accuser', 1),\n",
       " ('achieve', 1),\n",
       " ('acid', 1),\n",
       " ('acquisition', 1)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list_s = get_words(s_docs)\n",
    "word_list_s\n",
    "word_freq_table_s = get_doc_word_frequency(word_list_s, s_docs)\n",
    "tdm_s = pd.DataFrame(word_freq_table_s, columns=word_list_s)\n",
    "tdm_s\n",
    "\n",
    "freq_list_s = word_freq_table_s.sum(axis=0) \n",
    "freq_s = dict(zip(word_list_s,freq_list_s))\n",
    "freq_s.pop('') #ignoring spaces\n",
    "list(freq_s.items())[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 148),\n",
       " ('abbess', 1),\n",
       " ('ability', 1),\n",
       " ('able', 2),\n",
       " ('abolish', 1),\n",
       " ('abound', 1),\n",
       " ('about', 9),\n",
       " ('above', 1),\n",
       " ('absorbs', 1),\n",
       " ('academic', 2),\n",
       " ('accept', 2),\n",
       " ('accepted', 1),\n",
       " ('accessories', 1),\n",
       " ('accord', 1),\n",
       " ('according', 3),\n",
       " ('accounting', 2),\n",
       " ('accuse', 1),\n",
       " ('accused', 1),\n",
       " ('achaemenid', 1),\n",
       " ('achieve', 1)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list_q = get_words(q_docs)\n",
    "word_freq_table_q = get_doc_word_frequency(word_list_q, q_docs)\n",
    "tdm_q = pd.DataFrame(word_freq_table_q, columns=word_list_q)\n",
    "tdm_q\n",
    "\n",
    "freq_list_q = word_freq_table_q.sum(axis=0) \n",
    "freq_q = dict(zip(word_list_q,freq_list_q))\n",
    "\n",
    "freq_q.pop('') #removing spaces\n",
    "list(freq_q.items())[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "a = 1\n",
    "prob_s = []\n",
    "for count in freq_list_s:\n",
    "    #print(word, count)\n",
    "    prob_s.append((count+a)/(sum(freq_list_s)+len(freq_list_s)*a))\n",
    "    \n",
    "prob_s.append(a/(sum(freq_list_s)+len(freq_list_s)*a))\n",
    "    \n",
    "# Get word probabilities for question class\n",
    "\n",
    "prob_q = []\n",
    "for count in freq_list_q:\n",
    "    prob_q.append((count+a)/(sum(freq_list_q)+len(freq_list_q)*a))\n",
    "    \n",
    "prob_q.append(a/(sum(freq_list_q)+len(freq_list_q)*a))   \n",
    "\n",
    "\n",
    "def prior(className):    \n",
    "    denominator = len(s_docs) + len(q_docs)\n",
    "    \n",
    "    if className == 'statement':\n",
    "        numerator =  len(s_docs)\n",
    "    else:\n",
    "        numerator =  len(q_docs)\n",
    "        \n",
    "    return np.divide(numerator,denominator)\n",
    "    \n",
    "# Calculate class conditional probability for a sentence\n",
    "    \n",
    "def classCondProb(sentence, className):\n",
    "    words = get_words(sentence)\n",
    "    prob = 1\n",
    "    for word in words:\n",
    "            if className == 'statement':\n",
    "                idx = np.where(word_list_s == word)\n",
    "                \n",
    "                if np.array(idx).shape[1] != 0: \n",
    "                    prob = (prob * prob_s[np.array(idx)[0,0]]) \n",
    "                else:\n",
    "                    prob = (prob * prob_s[-1])\n",
    "                    \n",
    "            else: #if className is question\n",
    "                idx = np.where(word_list_q == word)\n",
    "                \n",
    "                if np.array(idx).shape[1] != 0: \n",
    "                    prob = (prob * prob_q[np.array(idx)[0,0]]) \n",
    "                else:\n",
    "                    prob = (prob * prob_q[-1])\n",
    "                \n",
    "    \n",
    "    return prob\n",
    "\n",
    "# Predict class of a sentence\n",
    "\n",
    "def predict(sentence):\n",
    "    prob_statement = classCondProb(sentence, 'statement') * prior('statement')\n",
    "    prob_question = classCondProb(sentence, 'question') * prior('question')\n",
    "    if  prob_statement > prob_question:\n",
    "        return 0 #statement\n",
    "    else:\n",
    "        return 1 #question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of our model is  0.755\n"
     ]
    }
   ],
   "source": [
    "#Getting the predicted values of the test set\n",
    "yhat_test = []\n",
    "for i in X_test:\n",
    "    yhat_test.append(predict(i))\n",
    "\n",
    "print ('The accuracy of our model is ',getAccuracy(y_test,yhat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used the NB Classifier to our new dataset and were able to get an accuracy of 0.78 to classify statements and questions. Using the value of the prior seems very important when the two classes had different values of probability among the dataset. \n",
    "\n",
    "This was a very simple classifier where we only included text as words in the lowercase and removed all numbers and special characters. This also discards word sequences and only takes into account word frequency. That is why it only performs slightly better than the prior for questions) as shown below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior for questions 0.6283333333333333\n",
      "Accuracy of our model 0.755\n"
     ]
    }
   ],
   "source": [
    "print('Prior for questions', prior('question'))\n",
    "print('Accuracy of our model', getAccuracy(y_test,yhat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So if our model predicted only questions for all values it would still have an accuracy of 0.61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
